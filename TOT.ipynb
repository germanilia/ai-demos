{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/germanilia/ai_and_stuff/blob/main/webinar_open_ai/demo/TOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "R03w43x7BK53"
      },
      "outputs": [],
      "source": [
        "#@title Set API Keys\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MeD_EdtLBOyT"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip -q install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjD6E9H_BSE5"
      },
      "outputs": [],
      "source": [
        "#@title Initilize LLM\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(\n",
        "    temperature=0.4,\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0jVKMfyGcfq"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "cot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "Think carefully and logically, explaining your answer.\n",
        "The question is: {question}\n",
        "\"\"\",\n",
        ")\n",
        "cot_chain = LLMChain(llm=llm, prompt=cot_prompt,verbose=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVj45-D_Bhxi"
      },
      "outputs": [],
      "source": [
        "tot_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"\n",
        "Imagine three different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "Then all experts will go on to the next step and write down this step of their thinking.\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue N times until the experts agree on the single most likely location\n",
        "The final answer must be the conclustion\n",
        "The question is: {question}\n",
        "\"\"\",\n",
        ")\n",
        "tot_chain = LLMChain(llm=llm, prompt=tot_prompt,verbose=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2Shj9sO6GbT_",
        "outputId": "c36a3c7d-ba9e-42e3-e8fd-18ea73f0aa92"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The single most likely location of the watch is in the towel that Carlos left at the snack bar.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"\"\"\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnXGGGvDGp0b",
        "outputId": "b128fe65-fe54-46b5-ca53-acb8f731b571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Think carefully and logically, explaining your answer.\n",
            "The question is: \n",
            "1. Carlos is at the swimming pool.\n",
            "2. He walks to the locker room, carrying a towel.\n",
            "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
            "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
            "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
            "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The single most likely location of Carlos' watch is in the towel that he had carried from the locker room to the lounger at the poolside. This is because he had put his watch in the towel before carrying it to the lounger. Although he had vigorously shaken the towel at the lounger, it is still possible that the watch could have fallen out of the towel without him noticing. It is less likely that the watch would be at the snack bar or the diving board since he did not mention taking the watch out of the towel or leaving it at those locations. Therefore, based on the information given, the most logical conclusion is that the watch is most likely in the towel that Carlos had carried to the lounger.\n"
          ]
        }
      ],
      "source": [
        "print(cot_chain.run(\"\"\"\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ5BqGNaFG38",
        "outputId": "67bd106d-c30d-47a7-ba7b-e9d3340075fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Imagine three different experts are answering this question.\n",
            "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
            "All experts will write down 1 step of their thinking,\n",
            "then share it with the group.\n",
            "They will each critique their response, and the all the responses of others\n",
            "They will check their answer based on science and the laws of physics\n",
            "Then all experts will go on to the next step and write down this step of their thinking.\n",
            "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
            "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
            "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
            "Each expert will assign a likelihood of their current assertion being correct\n",
            "Continue N times until the experts agree on the single most likely location\n",
            "The final answer must be the conclustion\n",
            "The question is: \n",
            "1. Carlos is at the swimming pool.\n",
            "2. He walks to the locker room, carrying a towel.\n",
            "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
            "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
            "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
            "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Expert 1:\n",
            "Step 1: Carlos puts his watch in the towel at the locker room.\n",
            "Critique: It's possible that the watch was not put in the towel at the locker room, but this is the most likely scenario given that he was carrying the towel at that point.\n",
            "\n",
            "Expert 2:\n",
            "Step 2: Carlos accidentally drops his watch while vigorously shaking the towel at the lounger.\n",
            "Critique: It's possible that the watch was lost at a different point, but this is a likely scenario given that he was shaking the towel vigorously.\n",
            "\n",
            "Expert 3:\n",
            "Step 3: The watch falls out of the towel when Carlos leaves it at the snack bar.\n",
            "Critique: It's possible that the watch was lost at a different point, but this is a likely scenario given that he left the towel unattended at the snack bar.\n",
            "\n",
            "Expert 1:\n",
            "Step 4: The watch was not on Carlos when he reached the diving board, so it must have been lost before that point.\n",
            "Critique: This seems like a logical conclusion based on the previous steps.\n",
            "\n",
            "Expert 2:\n",
            "Step 5: The most likely location of the watch is either at the lounger or the snack bar, but since he shook the towel vigorously at the lounger, it's more likely that the watch fell out there.\n",
            "Critique: This seems like a reasonable conclusion based on the previous steps.\n",
            "\n",
            "Expert 3:\n",
            "Step 6: Based on the previous steps, the single most likely location of the watch is at the lounger where Carlos vigorously shook the towel.\n",
            "Critique: This seems like a logical conclusion based on the previous steps.\n",
            "\n",
            "All experts agree that the single most likely location of the watch is at the lounger where Carlos vigorously shook the towel.\n"
          ]
        }
      ],
      "source": [
        "# Run the chain only specifying the input variable.\n",
        "print(tot_chain.run(\"\"\"\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch?\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JtLskqF-F5Yn",
        "outputId": "b02efc5a-03f6-4a88-c080-4e912848a226"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The ball is in the cup, which is upside down in the bedroom.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"\"\"\n",
        "Bob is in the living room.\n",
        "He walks to the kitchen, carrying a cup.\n",
        "He puts a ball in the cup and carries the cup to the bedroom.\n",
        "He turns the cup upside down, then walks to the garden.\n",
        "He puts the cup down in the garden, then walks to the garage.\n",
        "Where is the ball?\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNF-CtQpG6fx",
        "outputId": "86445d1e-4cf4-4d59-e1ad-e2b054250eeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Think carefully and logically, explaining your answer.\n",
            "The question is: \n",
            "Bob is in the living room.\n",
            "He walks to the kitchen, carrying a cup.\n",
            "He puts a ball in the cup and carries the cup to the bedroom.\n",
            "He turns the cup upside down, then walks to the garden.\n",
            "He puts the cup down in the garden, then walks to the garage.\n",
            "Where is the ball?\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The ball is in the bedroom, inside the cup that Bob carried from the kitchen. Bob never mentioned taking the ball out of the cup or leaving it anywhere else. Therefore, it can be assumed that the ball is still inside the cup when Bob turns it upside down in the bedroom.\n"
          ]
        }
      ],
      "source": [
        "print(cot_chain.run(\"\"\"\n",
        "Bob is in the living room.\n",
        "He walks to the kitchen, carrying a cup.\n",
        "He puts a ball in the cup and carries the cup to the bedroom.\n",
        "He turns the cup upside down, then walks to the garden.\n",
        "He puts the cup down in the garden, then walks to the garage.\n",
        "Where is the ball?\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQXlzGSHFP5L",
        "outputId": "690fe1ee-23c8-4fa2-92e2-b4a181f826bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Imagine three different experts are answering this question.\n",
            "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
            "All experts will write down 1 step of their thinking,\n",
            "then share it with the group.\n",
            "They will each critique their response, and the all the responses of others\n",
            "They will check their answer based on science and the laws of physics\n",
            "Then all experts will go on to the next step and write down this step of their thinking.\n",
            "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
            "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
            "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
            "Each expert will assign a likelihood of their current assertion being correct\n",
            "Continue N times until the experts agree on the single most likely location\n",
            "The final answer must be the conclustion\n",
            "The question is: \n",
            "Bob is in the living room.\n",
            "He walks to the kitchen, carrying a cup.\n",
            "He puts a ball in the cup and carries the cup to the bedroom.\n",
            "He turns the cup upside down, then walks to the garden.\n",
            "He puts the cup down in the garden, then walks to the garage.\n",
            "Where is the ball?\n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Expert 1:\n",
            "Based on the information given, the ball was put in the cup in the kitchen, and then the cup was taken to the bedroom. Therefore, the ball is most likely in the cup in the bedroom.\n",
            "\n",
            "Expert 2:\n",
            "I agree with Expert 1's reasoning, but we also need to consider the fact that the cup was turned upside down in the bedroom. It's possible that the ball fell out of the cup when it was turned upside down. Therefore, we should also check the bedroom to see if the ball is on the floor.\n",
            "\n",
            "Expert 3:\n",
            "I agree with both Experts 1 and 2. However, we also need to consider the possibility that Bob dropped the cup in the garden and the ball rolled out. We should check the garden to see if the ball is there.\n",
            "\n",
            "Expert 1:\n",
            "I agree with Expert 3's point. We need to check the garden as well. However, we also need to consider the fact that Bob could have dropped the cup in the garage and the ball could have rolled out there. We should check the garage as well.\n",
            "\n",
            "Expert 2:\n",
            "I agree with Expert 1's point. We need to check the garage as well. However, we also need to consider the fact that the cup was turned upside down in the bedroom. If the ball fell out of the cup, it could have rolled under the bed or into a corner. We should thoroughly search the bedroom.\n",
            "\n",
            "Expert 3:\n",
            "I agree with Expert 2's point. We need to thoroughly search the bedroom. However, we also need to consider the fact that the ball could have fallen out of the cup at any point during Bob's journey. We should check all the areas he walked through, including the living room and the kitchen.\n",
            "\n",
            "Expert 1:\n",
            "I agree with Expert 3's point. We need to check all the areas Bob walked through. However, we also need to consider the fact that the ball could have bounced out of the cup when Bob put it down in the garden. We should check the surrounding area in the garden as well.\n",
            "\n",
            "Expert 2:\n",
            "I agree with Expert 1's point. We need to check the surrounding area in the garden as well. However, we also need to consider the fact that the ball could have bounced out of the cup when Bob put it down in the garage. We should check the surrounding area in the garage as well.\n",
            "\n",
            "Expert 3:\n",
            "I agree with Expert 2's point. We need to check the surrounding area in the garage as well. Based on all the possibilities, I would assign a likelihood of 70% that the ball is in the cup in the bedroom, a likelihood of 20% that the ball is on the floor in the bedroom, and a likelihood of 10% that the ball is in the garden or garage.\n",
            "\n",
            "Final Answer:\n",
            "Based on our thorough analysis, the most likely location of the ball is in the cup in the bedroom. However, we should also check the surrounding area in the bedroom, as well as all the areas Bob walked through, including the living room, kitchen, garden, and garage.\n"
          ]
        }
      ],
      "source": [
        "print(tot_chain.run(\"\"\"\n",
        "Bob is in the living room.\n",
        "He walks to the kitchen, carrying a cup.\n",
        "He puts a ball in the cup and carries the cup to the bedroom.\n",
        "He turns the cup upside down, then walks to the garden.\n",
        "He puts the cup down in the garden, then walks to the garage.\n",
        "Where is the ball?\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1iYCtqZ97L4g"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "repo_id1 = \"gpt2\"\n",
        "repo_id2 = \"facebook/opt-350m\"\n",
        "\n",
        "llm_1 = OpenAI(temperature=0.7, max_tokens=3000)\n",
        "llm_2 = HuggingFaceHub(repo_id=repo_id1, model_kwargs={\"temperature\":0.1, \"max_length\":500})\n",
        "llm_3 = HuggingFaceHub(repo_id=repo_id2, model_kwargs={\"temperature\":0.1, \"max_length\":500})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cKDRQXyP7hHl"
      },
      "outputs": [],
      "source": [
        "template_1 = \"\"\"Imagine three different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "All experts will write down 1 step of their thinking,\n",
        "then share it with the group.\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer based on science and the laws of physics\n",
        "Then all experts will go on to the next step and write down this step of their thinking.\n",
        "They will keep going through steps until they reach their conclusion taking into account the thoughts of the other experts\n",
        "If at any time they realise that there is a flaw in their logic they will backtrack to where that flaw occurred\n",
        "If any expert realises they're wrong at any point then they acknowledges this and start another train of thought\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is {question}\n",
        "\n",
        "The experts reasoning is...\n",
        "\"\"\"\n",
        "\n",
        "template_2 = \"\"\"Imagine six different experts are answering this question.\n",
        "They will brainstorm the answer step by step reasoning carefully and taking all facts into consideration\n",
        "Each expert will share their first step with all of the other experts\n",
        "They will each critique their response, and the all the responses of others\n",
        "They will check their answer being careful to think through any consequences\n",
        "Each expert will then write down the next step of their thought process\n",
        "Each expert will assign a likelihood of their current assertion being correct\n",
        "Continue until the experts agree on the single most likely location\n",
        "The question is {question}\n",
        "\n",
        "The experts reasoning is...\n",
        "\"\"\"\n",
        "\n",
        "template_3 = \"\"\"Imagine four different experts are answering this question.\n",
        "They will first write down all the facts\n",
        "They will then consider three different alternative answers and communicate these answers to the other experts\n",
        "they will write down the likelihood of each answer\n",
        "Based on this they will each come up with a single answer\n",
        "The question is {question}\n",
        "\n",
        "The experts reasoning is...\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "question = \"\"\"1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch. Where is the single most likely location of the watch? \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6ltjtao7kMu"
      },
      "outputs": [],
      "source": [
        "prompt1 = PromptTemplate(template=template_1, input_variables=[\"question\"])\n",
        "prompt2 = PromptTemplate(template=template_2, input_variables=[\"question\"])\n",
        "prompt3 = PromptTemplate(template=template_3, input_variables=[\"question\"])\n",
        "\n",
        "llm_chain_1 = LLMChain(prompt=prompt1, llm=llm_1)\n",
        "llm_chain_2 = LLMChain(prompt=prompt2, llm=llm_2)\n",
        "llm_chain_3 = LLMChain(prompt=prompt3, llm=llm_3)\n",
        "\n",
        "response_1 = llm_chain_1.run(question)\n",
        "response_2 = llm_chain_2.run(question)\n",
        "response_3 = llm_chain_3.run(question)\n",
        "\n",
        "print(response_1)\n",
        "print(response_2)\n",
        "print(response_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69Ahguz07mhu"
      },
      "outputs": [],
      "source": [
        "get_together = \"\"\"Several experts have been asked this question\n",
        "1. Carlos is at the swimming pool.\n",
        "2. He walks to the locker room, carrying a towel.\n",
        "3. He puts his watch in the towel and carries the towel tightly to a lounger at the poolside.\n",
        "4. At the lounger he opens and vigorously shakes the towel, then walks to the snack bar.\n",
        "5. He leaves the towel at the snack bar, then walks to the diving board.\n",
        "6. Later Carlos realises he has has lost his watch.\n",
        "Where is the single most likely location of the watch? their resulting answers are {answer}\n",
        "which answer is most likely?\n",
        "The most likely answer is...\"\"\"\n",
        "\n",
        "answer = response_1+response_2+response_3\n",
        "fusion = PromptTemplate(template=get_together, input_variables=[\"answer\"])\n",
        "\n",
        "wood_for_trees = OpenAI(temperature=0.1, max_tokens=3000)\n",
        "final = LLMChain(prompt=fusion, llm=wood_for_trees)\n",
        "conclusion = final.run(answer)\n",
        "\n",
        "print(f\"Conclusion is {conclusion}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPsHWKIho5NlV4n5lWfJoAy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
